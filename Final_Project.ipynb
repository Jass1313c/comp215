{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSotKNt6ERa0Fj3KP70Suy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jass1313c/comp215/blob/main/Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqEZ4aNRYr4F"
      },
      "outputs": [],
      "source": [
        "import datetime, json, requests\n",
        "from pprint import pprint\n",
        "\n",
        "param = { \"format\": \"geojson\", \"starttime\": \"2024-03-10\",\"limit\": 20000, \"endtime\": \"2024-05-30\"}\n",
        "url = \"https://earthquake.usgs.gov/fdsnws/event/1/query\"\n",
        "response = requests.get(url, params=param)\n",
        "data = json.loads(response.text)\n",
        "\n",
        "#pprint(data)\n",
        "\n",
        "for feature in data['features']:\n",
        "  depth = feature['geometry']['coordinates'][2]\n",
        "  if depth < 10 and \"Texas\" in feature['properties']['place']:\n",
        "    Latitude = feature['geometry']['coordinates'][1]\n",
        "    Longitude = feature['geometry']['coordinates'][0]\n",
        "    print(f\"Mag: {feature['properties']['mag']},   Place: {feature['properties']['place']},   Time: {datetime.datetime.fromtimestamp(feature['properties']['time'] / 1000)},   Lat: {Latitude},   Long: {Longitude}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oHN-g9Pg7cX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime, json, requests\n",
        "from pprint import pprint\n",
        "\n",
        "param = { \"format\": \"geojson\", \"starttime\": \"2024-03-14\",\"limit\": 20000, \"endtime\": \"2024-06-15\", \"minmagnitude\": 1}\n",
        "url = \"https://earthquake.usgs.gov/fdsnws/event/1/query\"\n",
        "response = requests.get(url, params=param)\n",
        "data = json.loads(response.text)\n",
        "\n",
        "count = 0\n",
        "earthquake_data = []\n",
        "\n",
        "for feature in data['features']:\n",
        "  depth = feature['geometry']['coordinates'][2]\n",
        "  if depth < 10 and \"Texas\" in feature['properties']['place']:\n",
        "    count += 1\n",
        "\n",
        "    earthquake_data.append({\n",
        "      \"Mag\": feature['properties']['mag'],\n",
        "      \"Place\": feature['properties']['place'],\n",
        "      \"Time\": datetime.datetime.fromtimestamp(feature['properties']['time'] / 1000),\n",
        "      \"Lat\": feature['geometry']['coordinates'][1],\n",
        "      \"Long\": feature['geometry']['coordinates'][0],\n",
        "      \"Depth\": depth\n",
        "    })\n",
        "\n",
        "pprint(earthquake_data)\n",
        "pprint(f\"Count: {count}\")"
      ],
      "metadata": {
        "id": "aKbUrbmnSwyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "file_path = '/content/drive/MyDrive/Fracking.csv'\n",
        "fracking_df = pd.read_csv(file_path)\n",
        "with open(file_path, 'r') as file:\n",
        "    fracking_df = pd.read_csv(file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RRl_3C-XVWt",
        "outputId": "d597c731-4d7e-4fe7-fc3a-2e726759bb78"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from geopy.distance import geodesic\n",
        "\n",
        "# Load fracking data\n",
        "file_path = '/content/drive/MyDrive/Fracking.csv'\n",
        "fracking_df = pd.read_csv(file_path)\n",
        "\n",
        "# Convert JobStartDate & JobEndDate to datetime\n",
        "fracking_df[\"JobStartDate\"] = pd.to_datetime(fracking_df[\"JobStartDate\"])\n",
        "fracking_df[\"JobEndDate\"] = pd.to_datetime(fracking_df[\"JobEndDate\"])\n",
        "\n",
        "# Create a DataFrame for earthquake data\n",
        "df_quakes = pd.DataFrame([\n",
        "    {'Depth': 6.7871, 'Lat': 32.43, 'Long': -102.144, 'Mag': 1.4, 'Place': '38 km SSW of Los Ybanez, Texas', 'Time': datetime.datetime(2024, 6, 12, 17, 54, 44, 924000)},\n",
        "    {'Depth': 6.5186, 'Lat': 28.494, 'Long': -98.631, 'Mag': 2.0, 'Place': '8 km WNW of Tilden, Texas', 'Time': datetime.datetime(2024, 6, 12, 17, 16, 50, 386000)},\n",
        "    {'Depth': 5.9332, 'Lat': 31.647, 'Long': -104.02, 'Mag': 1.6, 'Place': '40 km W of Mentone, Texas', 'Time': datetime.datetime(2024, 6, 12, 17, 7, 30, 664000)},\n",
        "    {'Depth': 9.5459, 'Lat': 32.409, 'Long': -102.089, 'Mag': 1.3, 'Place': '37 km WSW of Ackerly, Texas', 'Time': datetime.datetime(2024, 6, 12, 16, 58, 8, 809000)},\n",
        "    {'Depth': 7.3944, 'Lat': 31.704, 'Long': -104.159, 'Mag': 1.8, 'Place': '53 km W of Mentone, Texas', 'Time': datetime.datetime(2024, 6, 12, 16, 34, 51, 955000)},\n",
        "    {'Depth': 8.2019, 'Lat': 31.512, 'Long': -104.015, 'Mag': 2.4, 'Place': '30 km NW of Toyah, Texas', 'Time': datetime.datetime(2024, 6, 12, 3, 25, 17, 553000)},\n",
        "    {'Depth': 5.7861, 'Lat': 32.433, 'Long': -102.139, 'Mag': 1.4, 'Place': '37 km SSW of Los Ybanez, Texas', 'Time': datetime.datetime(2024, 6, 12, 2, 25, 7, 588000)}\n",
        "])\n",
        "\n",
        "# Iterate over earthquake data and check for matches\n",
        "matched_data = []\n",
        "\n",
        "for _, quake in df_quakes.iterrows():\n",
        "    quake_time = quake[\"Time\"]\n",
        "    quake_location = (quake[\"Lat\"], quake[\"Long\"])\n",
        "\n",
        "    for _, frack in fracking_df.iterrows():\n",
        "        frack_location = (frack[\"Latitude\"], frack[\"Longitude\"])\n",
        "\n",
        "        # Check if earthquake is within 10 km of fracking site\n",
        "        if geodesic(quake_location, frack_location).km <= 10:\n",
        "            # Check if earthquake happened during or after fracking job\n",
        "            if frack[\"JobStartDate\"] <= quake_time <= frack[\"JobEndDate\"]:\n",
        "                matched_data.append({\n",
        "                    \"Frack_Well\": frack[\"DisclosureId\"],\n",
        "                    \"Frack_Start\": frack[\"JobStartDate\"],\n",
        "                    \"Frack_End\": frack[\"JobEndDate\"],\n",
        "                    \"Earthquake_Time\": quake_time,\n",
        "                    \"Mag\": quake[\"Mag\"],\n",
        "                    \"Depth\": quake[\"Depth\"],\n",
        "                    \"Distance_km\": geodesic(quake_location, frack_location).km\n",
        "                })\n",
        "\n",
        "# Convert matched results to DataFrame\n",
        "matched_df = pd.DataFrame(matched_data)\n",
        "\n",
        "# Save to CSV for further analysis\n",
        "matched_df.to_csv(\"/mnt/data/Matched_Earthquake_Fracking.csv\", index=False)\n",
        "\n",
        "print(f\"Matched events: {len(matched_df)}\")\n",
        "print(matched_df.head())\n"
      ],
      "metadata": {
        "id": "9JdSQAg_e4bc",
        "outputId": "5fab9ee7-8509-4420-eeff-aa50157ced74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-cc26aea9b426>:9: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  fracking_df[\"JobStartDate\"] = pd.to_datetime(fracking_df[\"JobStartDate\"])\n",
            "<ipython-input-37-cc26aea9b426>:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  fracking_df[\"JobEndDate\"] = pd.to_datetime(fracking_df[\"JobEndDate\"])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Cannot save file into a non-existent directory: '/mnt/data'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-cc26aea9b426>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# Save to CSV for further analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mmatched_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/mnt/data/Matched_Earthquake_Fracking.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Matched events: {len(matched_df)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 )\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3965\u001b[0m         )\n\u001b[1;32m   3966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3967\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3968\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3969\u001b[0m             \u001b[0mlineterminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlineterminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         )\n\u001b[0;32m-> 1014\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \"\"\"\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# apply compression and byte/text conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         with get_handle(\n\u001b[0m\u001b[1;32m    252\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[0;31m# Only for write methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0mcheck_parent_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mrf\"Cannot save file into a non-existent directory: '{parent}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '/mnt/data'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from geopy import distance\n",
        "newport_ri = (41.49008, -71.312796)\n",
        "cleveland_oh = (41.499498, -81.695391)\n",
        "print(distance.distance(newport_ri, cleveland_oh).km)"
      ],
      "metadata": {
        "id": "UB8f3pC8PGpS",
        "outputId": "5b6e0ccb-3e4e-47d7-acb4-b3f2f6a67df2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "866.4554329098685\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import pyproj\n",
        "import pandas as pd\n",
        "\n",
        "# Define source projection (NAD 83)\n",
        "source_proj = pyproj.Proj('epsg:4269')\n",
        "\n",
        "# Define target projection (WGS 84)\n",
        "target_proj = pyproj.Proj('epsg:4326')\n",
        "\n",
        "# Assuming you have latitude and longitude as individual variables\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame({'Latitude': [Latitude], 'Longitude': [Longitude]})\n",
        "\n",
        "# Create new columns for projected coordinates\n",
        "df['Latitude_WGS84'], df['Longitude_WGS84'] = pyproj.transform(source_proj, target_proj, df['Longitude'].values, df['Latitude'].values)\n",
        "\n",
        "print(df)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Nu_6oXlpWD3-",
        "outputId": "be60d671-2855-4816-8712-9388ab2dfca8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Latitude  Longitude  Latitude_WGS84  Longitude_WGS84\n",
            "0    31.014   -103.254        -103.254           31.014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-2e97aa9c9552>:15: FutureWarning: This function is deprecated. See: https://pyproj4.github.io/pyproj/stable/gotchas.html#upgrading-to-pyproj-2-from-pyproj-1\n",
            "  df['Latitude_WGS84'], df['Longitude_WGS84'] = pyproj.transform(source_proj, target_proj, df['Longitude'].values, df['Latitude'].values)\n"
          ]
        }
      ]
    }
  ]
}